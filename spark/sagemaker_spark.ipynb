{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"FeatureGroupSchema\").getOrCreate()\n",
    "\n",
    "# Replace 'your-feature-group-name' with the actual name of your feature group\n",
    "feature_group_name = 'your-feature-group-name'\n",
    "\n",
    "# Fetch the feature definition data from the SageMaker Feature Group\n",
    "feature_group = sagemaker.FeatureGroup(name=feature_group_name)\n",
    "description = feature_group.describe()\n",
    "feature_definitions = description['FeatureDefinitions']\n",
    "\n",
    "# Define a list to store StructField objects\n",
    "fields = []\n",
    "\n",
    "# Iterate through the feature definitions and create StructField objects\n",
    "for feature in feature_definitions:\n",
    "    field_name = feature['FeatureName']\n",
    "    field_type = feature['FeatureType']\n",
    "    \n",
    "    # Map SageMaker Feature Types to PySpark DataTypes (you may need to adjust this mapping based on your use case)\n",
    "    if field_type == 'Integral':\n",
    "        data_type = StringType()  # Change this to IntegerType() if necessary\n",
    "    elif field_type == 'Fractional':\n",
    "        data_type = StringType()  # Change this to DoubleType() if necessary\n",
    "    elif field_type == 'String':\n",
    "        data_type = StringType()\n",
    "    else:\n",
    "        data_type = StringType()  # Default to StringType()\n",
    "\n",
    "    fields.append(StructField(field_name, data_type, nullable=True))\n",
    "\n",
    "# Create a StructType schema using the defined fields\n",
    "schema = StructType(fields)\n",
    "\n",
    "# Print the created schema\n",
    "print(\"Spark Schema:\")\n",
    "print(schema)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from sagemaker_pyspark import (SageMakerSession, \n",
    "                               FeatureStore)\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"FeatureGroupSchema\").getOrCreate()\n",
    "\n",
    "# Replace 'your-feature-group-name' with the actual name of your feature group\n",
    "feature_group_name = 'your-feature-group-name'\n",
    "\n",
    "# Initialize a SageMaker session\n",
    "sagemaker_session = SageMakerSession(spark)\n",
    "\n",
    "# Create a FeatureStore instance\n",
    "feature_store = FeatureStore(session=sagemaker_session)\n",
    "\n",
    "# Get the Spark schema for the specified feature group\n",
    "schema = feature_store.schema_of_feature_group(feature_group_name)\n",
    "\n",
    "# Print the schema\n",
    "print(\"Spark Schema:\")\n",
    "print(schema)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
